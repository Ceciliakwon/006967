{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN_tensorflow.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ceciliakwon/006967/blob/master/GAN_tensorflow(example).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "99rSFcx229YP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t3LoCV8d3Rt1",
        "colab_type": "code",
        "outputId": "7864ab68-7ac9-4404-f9eb-7495bb1f9236",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets(\"MNIST_data\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MprdRrTk3SVp",
        "colab_type": "code",
        "outputId": "0a05f0b1-6df2-44db-b58e-995562af57c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "train_x = mnist.train.images\n",
        "train_y = mnist.train.labels\n",
        "\n",
        "print(train_x.shape, train_y.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(55000, 784) (55000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MO2siZ3P3UQA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "total_epochs = 100\n",
        "batch_size = 100\n",
        "learning_rate = 0.0002"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "98f7_t4s3V2N",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def generator( z , reuse = False ) :\n",
        "    if reuse==False :\n",
        "        with tf.variable_scope(name_or_scope = \"Gen\") as scope :\n",
        "            gw1 = tf.get_variable(name = \"w1\",\n",
        "                                  shape = [128, 256],\n",
        "                                  initializer= tf.random_normal_initializer(mean=0.0, stddev = 0.01))\n",
        "            # quiz : weight 의 초깃값을 random normal 로 주는 이유는 무엇일까요?\n",
        "\n",
        "            gb1 = tf.get_variable(name = \"b1\",\n",
        "                                 shape = [256],\n",
        "                                 initializer = tf.random_normal_initializer(mean=0.0, stddev = 0.01))\n",
        "\n",
        "            gw2 = tf.get_variable(name = \"w2\",\n",
        "                                  shape = [256, 784],\n",
        "                                  initializer= tf.random_normal_initializer(mean=0.0, stddev = 0.01))\n",
        "\n",
        "            gb2 = tf.get_variable(name = \"b2\",\n",
        "                                 shape = [784],\n",
        "                                 initializer = tf.random_normal_initializer(mean=0.0, stddev = 0.01))\n",
        "    else :\n",
        "        with tf.variable_scope(name_or_scope=\"Gen\", reuse = True) as scope :\n",
        "            gw1 = tf.get_variable(name = \"w1\",\n",
        "                                  shape = [128, 256],\n",
        "                                  initializer= tf.random_normal_initializer(mean=0.0, stddev = 0.01))\n",
        "\n",
        "            gb1 = tf.get_variable(name = \"b1\",\n",
        "                                 shape = [256],\n",
        "                                 initializer = tf.random_normal_initializer(mean=0.0, stddev = 0.01))\n",
        "\n",
        "            gw2 = tf.get_variable(name = \"w2\",\n",
        "                                  shape = [256, 784],\n",
        "                                  initializer= tf.random_normal_initializer(mean=0.0, stddev = 0.01))\n",
        "\n",
        "            gb2 = tf.get_variable(name = \"b2\",\n",
        "                                 shape = [784],\n",
        "                                 initializer = tf.random_normal_initializer(mean=0.0, stddev = 0.01))\n",
        "\n",
        "\n",
        "    hidden = tf.nn.relu( tf.matmul(z , gw1) + gb1 )\n",
        "    output = tf.nn.sigmoid( tf.matmul(hidden, gw2) + gb2 )   #출력층에 시그모이드를 쓰는 이유는 무엇일까요?\n",
        "\n",
        "    return output   #[784] 가짜 생성된 이미지\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o9Nqxm8w3bf3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def discriminator( x , reuse = False) :\n",
        "\n",
        "    if(reuse == False) :\n",
        "        with tf.variable_scope(name_or_scope=\"Dis\") as scope :\n",
        "            dw1 = tf.get_variable(name = \"w1\",\n",
        "                                  shape = [784, 256],\n",
        "                                  initializer = tf.random_normal_initializer(0.0, 0.01) )\n",
        "            db1 = tf.get_variable(name = \"b1\",\n",
        "                                  shape = [256],\n",
        "                                  initializer = tf.random_normal_initializer(0.0, 0.01) )\n",
        "            dw2 = tf.get_variable(name = \"w2\",\n",
        "                                  shape = [256, 1],\n",
        "                                  initializer = tf.random_normal_initializer(0.0, 0.01) )\n",
        "            db2 = tf.get_variable(name = \"b2\",\n",
        "                                  shape = [1],\n",
        "                                  initializer = tf.random_normal_initializer(0.0, 0.01) )\n",
        "    else :\n",
        "        with tf.variable_scope(name_or_scope=\"Dis\", reuse = True) as scope :\n",
        "            dw1 = tf.get_variable(name = \"w1\",\n",
        "                                  shape = [784, 256],\n",
        "                                  initializer = tf.random_normal_initializer(0.0, 0.01) )\n",
        "            db1 = tf.get_variable(name = \"b1\",\n",
        "                                  shape = [256],\n",
        "                                  initializer = tf.random_normal_initializer(0.0, 0.01) )\n",
        "            dw2 = tf.get_variable(name = \"w2\",\n",
        "                                  shape = [256, 1],\n",
        "                                  initializer = tf.random_normal_initializer(0.0, 0.01) )\n",
        "            db2 = tf.get_variable(name = \"b2\",\n",
        "                                  shape = [1],\n",
        "                                  initializer = tf.random_normal_initializer(0.0, 0.01) )\n",
        "\n",
        "    hidden = tf.nn.relu( tf.matmul(x , dw1) + db1 )  #[-, 256]\n",
        "    output = tf.nn.sigmoid( tf.matmul(hidden, dw2)  + db2 )   #[-, 1]  진품인지(1) 가품인지(0)의 label 결과값\n",
        "\n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W221YKBt3eBC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def random_noise(batch_size) :\n",
        "    return np.random.normal(size=[batch_size , 128])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qF6d79W43gbT",
        "colab_type": "code",
        "outputId": "f718beb6-6345-4cb3-9df8-206a0290c23f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "cell_type": "code",
      "source": [
        "g = tf.Graph()\n",
        "\n",
        "with g.as_default() :\n",
        "\n",
        "    ######################################################\n",
        "    # 1 .Feedable part  :: 그래프에서 유일하게 데이터가 유입될 수 있는 장소\n",
        "    ######################################################\n",
        "\n",
        "    X = tf.placeholder(tf.float32, [None, 784]) #GAN 은 autoencoder 와 마찬가지로 unsupervised learning 이므로 y(label)을 사용하지 않습니다.\n",
        "\n",
        "    Z = tf.placeholder(tf.float32, [None, 128]) #Z 는 생성기의 입력값으로 사용될 노이즈 입니다.\n",
        "\n",
        "\n",
        "    ################################\n",
        "    # 2. generator 와 discriminator 의 사용\n",
        "    ##################################\n",
        "\n",
        "\n",
        "    fake_x = generator(Z)\n",
        "\n",
        "    result_of_fake = discriminator(fake_x)\n",
        "    result_of_real = discriminator(X , True)\n",
        "\n",
        "\n",
        "    ################################\n",
        "    # 3. Loss( 성취도평가 ) : g_loss 와 d_loss\n",
        "\n",
        "    # g_loss & d_loss 모두 높을 수록 좋다.\n",
        "    # g_loss : 얼마나 fake_x 가 진짜같은가\n",
        "    # d_loss : 얼마나 discriminator 가 정확한가\n",
        "\n",
        "    # 두 수치를 모두 높이도록 train 하면 생성기와 분류기의 성능이 모두 올라간다.\n",
        "    ################################\n",
        "\n",
        "    g_loss = tf.reduce_mean( tf.log(result_of_fake) )\n",
        "    d_loss = tf.reduce_mean( tf.log(result_of_real) + tf.log(1 - result_of_fake) )\n",
        "\n",
        "\n",
        "    ################################\n",
        "    # 4. Train : Maximizing g_loss & d_loss\n",
        "    ################################\n",
        "\n",
        "    t_vars = tf.trainable_variables() # return list\n",
        "\n",
        "    g_vars = [var for var in t_vars if \"Gen\" in var.name]\n",
        "    d_vars = [var for var in t_vars if \"Dis\" in var.name]\n",
        "\n",
        "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
        "\n",
        "    g_train = optimizer.minimize(-g_loss, var_list= g_vars)\n",
        "    d_train = optimizer.minimize(-d_loss, var_list = d_vars)    \n",
        "\n",
        "    # g_loss & d_loss 를 최대화 시켜야하는데 minimize 함수밖에 없기 때문에 - 음수부호 붙인다.\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "moYaWtUA3i44",
        "colab_type": "code",
        "outputId": "a8f81f1d-4c2b-42ac-9d4a-f90460ba3c01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        }
      },
      "cell_type": "code",
      "source": [
        "with tf.Session(graph = g) as sess :\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "\n",
        "    total_batchs = int(train_x.shape[0] / batch_size)\n",
        "\n",
        "    for epoch in range(total_epochs) :\n",
        "\n",
        "        for batch in range(total_batchs) :\n",
        "            batch_x = train_x[batch * batch_size : (batch+1) * batch_size]  # [batch_size , 784]\n",
        "            batch_y = train_y[batch * batch_size : (batch+1) * batch_size]  # [batch_size,]\n",
        "            noise = random_noise(batch_size)  # [batch_size, 128]\n",
        "\n",
        "            sess.run(g_train , feed_dict = {Z : noise})\n",
        "            sess.run(d_train, feed_dict = {X : batch_x , Z : noise})\n",
        "\n",
        "            gl, dl = sess.run([g_loss, d_loss], feed_dict = {X : batch_x , Z : noise})\n",
        "\n",
        "\n",
        "        #매 20 epoch 마다 학습된 성능을 중간점검  (실제론 더 자주하시는 것이 좋습니다. )\n",
        "        if (epoch+1) % 20 == 0 or epoch == 1  :\n",
        "            print(\"=======Epoch : \", epoch , \" =======================================\")\n",
        "            print(\"생성기 성능 : \" ,gl )\n",
        "            print(\"분류기 성능 : \" ,dl )\n",
        "            print(\"생성기와 분류기 선의의 경쟁중...\")\n",
        "\n",
        "\n",
        "        #10개의 epoch 마다 Generator 가 만들어내는 실제 결과물을 얻어보며 , 성능 발전을 시각적으로 확인\n",
        "        \n",
        "        if epoch == 0 or (epoch + 1) % 10 == 0  :\n",
        "            sample_noise = random_noise(10)\n",
        "\n",
        "            generated = sess.run(fake_x , feed_dict = { Z : sample_noise})\n",
        "\n",
        "            fig, ax = plt.subplots(1, 10, figsize=(10, 1))\n",
        "            for i in range(10) :\n",
        "                ax[i].set_axis_off()\n",
        "                ax[i].imshow( np.reshape( generated[i], (28, 28)) )\n",
        "\n",
        "            plt.savefig('{}.png'.format(str(epoch).zfill(3)), bbox_inches='tight') #디렉토리 생성 필요\n",
        "            plt.close(fig)\n",
        "\n",
        "\n",
        "    print('최적화 완료!')\n",
        "      \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=======Epoch :  1  =======================================\n",
            "생성기 성능 :  -2.2183056\n",
            "분류기 성능 :  -0.29033893\n",
            "생성기와 분류기 선의의 경쟁중...\n",
            "=======Epoch :  19  =======================================\n",
            "생성기 성능 :  -2.041587\n",
            "분류기 성능 :  -0.52517855\n",
            "생성기와 분류기 선의의 경쟁중...\n",
            "=======Epoch :  39  =======================================\n",
            "생성기 성능 :  -2.087244\n",
            "분류기 성능 :  -0.3640161\n",
            "생성기와 분류기 선의의 경쟁중...\n",
            "=======Epoch :  59  =======================================\n",
            "생성기 성능 :  -1.4709079\n",
            "분류기 성능 :  -0.79524237\n",
            "생성기와 분류기 선의의 경쟁중...\n",
            "=======Epoch :  79  =======================================\n",
            "생성기 성능 :  -1.4958202\n",
            "분류기 성능 :  -0.6640295\n",
            "생성기와 분류기 선의의 경쟁중...\n",
            "=======Epoch :  99  =======================================\n",
            "생성기 성능 :  -1.8037335\n",
            "분류기 성능 :  -0.45991316\n",
            "생성기와 분류기 선의의 경쟁중...\n",
            "최적화 완료!\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}